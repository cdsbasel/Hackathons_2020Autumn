---
title: "Sentiment"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  eval = FALSE,
  message = FALSE,
  warning = FALSE)
```

<img src="https://dwulff.github.io/NLP_2020Autumn/assets/img/text_sm.png" width="100%"></img>

# {.tabset}

## Overview

In this assignment you will...

- perform sentiment analysis.
- plot the emotional arc of several books.

## Tasks

### A - Gather books

1) Go to [Project Gutenberg](https://www.gutenberg.org/) and download five books that you find interesting (you may reuse the book you've been using). Make sure that the books do not drastically differ in length. The smallest book should be more than 50% of the size of the largest book. 

### B - Process books

1. Define a function called `main_text_fun` that takes as input the filename (incl. path) and returns the `main_text` object from previous assignments containing the lower-case book text. 

```{r}

# function extracting main text
main_text_fun = function(file){
  
    # load text
  text = read_file(file)
  
  # define regex
  regex = '\\*{3}[:print:]*\\*{3}'
  
  # cut text into sections
  text_split = str_split(text, '\\*{3}[:print:]*\\*{3}')
  
  # get sections
  sections = text_split[[1]]
  
  # select main text
  main_text = sections[2]
  
  # out
  main_text
  }
  
```

2. Create a vector containing filenames (incl. path) of the books. If the books are all in one folder you can use `list.files()` with `full.names = TRUE`.    

```{r}
# file
files = list.files('books', full.names = T)

```

3. Use the vector and the `main_text_fun()` within a `sapply()` to extract the texts for all books and store them in an object called `texts`.   

```{r}

# process texts
texts <- sapply(files, main_text_fun)

```

4. Create a `tibble` using `tibble` that has two columns: a column called `book` containing a self-defined character vector of book names and a column called `text` containing the `texts` vector of books. Call the tibble `text_tbl`. When you subsequently print it it should like the output shown below. 

```{r, eval = TRUE}

# as tibble
text_tbl = tibble(book = c('Alice in Wonderland','Dorian Gray', 
                          'Huckleberry Finn', 'Peter Pan', 'Treasure Island'), 
                  text = texts)

# print
text_tbl
```

### C - Tokenization

1) Apply `unnest_tokens()` to `token_tbl` in order to tokenize the text. Store the result back in `token_tbl`. 

```{r}
# tokenize
token_tbl = text_tbl %>% 
  unnest_tokens(word, text)
```

2) Now use `tidyverse`'s `group_by()` and `mutate()` idiom to add columns `pos = 1:n()` and `rel_pos = (pos-1) / max(pos-1)` coding the absolute and relative position of a word within the respective book. To do this you must group according to the variable indicating the book. 

```{r}
# add pos variable
token_tbl <- token_tbl %>% 
  group_by(book) %>%
  mutate(pos = 1:n(),
         rel_pos = pos / max(pos)) %>%
  ungroup()
```

## D - Sentiment analysis

1) Extract the *afinn* sentiment dictionary using the `get_sentiments` function and store it in an object called `afinn`.

2) Use `inner_join` to combine your `token_tbl` with `afinn`.

```{r, eval = TRUE}
# add sentiments
token_tbl <- token_tbl %>% 
  inner_join(get_sentiments("afinn"))
```

## Smoothing

1. Use the `group_by` - `mutate` idiom along with the smooth function below to calculate more interpretable, smoothed sentiment scores for each of the books. 

```{r, echo = TRUE, eval = TRUE}

# smoothing function
smooth = function(pos, score){ 
  sm = sapply(pos, function(x) {
    weights = dnorm(pos, x, max(pos) / 10)
    sum(score * (weights / sum(weights)))
    })
  }

```

```{r, eval = TRUE}

# smooth scores
token_tbl <- token_tbl %>% 
  group_by(book) %>%
  mutate(smooth_score = smooth(pos, score))


```

2. Use the code below to create a plot like this:

```{r, eval = TRUE, echo = TRUE}

ggplot(token_tbl, 
       aes(rel_pos, smooth_score,color=book)) +
  geom_line(lwd=2) + 
  labs(x = "Position", y = 'Sentiment')


```


